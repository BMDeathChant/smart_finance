"""
æ•°æ®çˆ¬å–ä¸åˆ†æä¸»ç¨‹åº - Flask Webç‰ˆæœ¬
æ•´åˆè¡¨æ ¼çˆ¬å–ã€æ•°æ®æ¸…æ´—ã€åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½
"""

from flask import Flask, render_template, request, redirect, url_for, send_from_directory, jsonify
from dash import html
from table_scraper import TableScraper
from data_cleaner import DataCleaner
from data_visualizer import DataVisualizer
from openai_wrapper import AIDataAssistant
from number_converter import NumberConverter
from data_cleaner import DataCleaner
from du_point_unit import create_app as create_du_point_app, run_app
import pandas as pd
import logging
import os
from dotenv import load_dotenv
from io import StringIO
import sys
import markdown # å¯¼å…¥ markdown åº“



from io import StringIO
import logging
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)
class LogCollector:
    def __init__(self):
        self.log_buffer = StringIO()
        #self.logger = logging.getLogger('smart_logger')
        #self.logger.setLevel(logging.INFO)
        self.handler = logging.StreamHandler(self.log_buffer)
        self.handler.setFormatter(logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(message)s',datefmt='%Y-%m-%d %H:%M:%S'))
        

        # ç»‘å®šåˆ° root loggerï¼Œç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½ä¼šè¿›æ¥
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        root_logger.addHandler(self.handler)
        # é¿å…é‡å¤æ·»åŠ  handler
        if not any(isinstance(h, logging.StreamHandler) for h in root_logger.handlers):
            root_logger.addHandler(self.handler)

        # æ¯æ¬¡ç¨‹åºå¯åŠ¨æ—¶æ¸…ç©ºæ—¥å¿—ç¼“å­˜
        self.log_buffer.truncate(0)
        self.log_buffer.seek(0)

    def get_logs(self):
        self.log_buffer.seek(0)
        logs = []
        for line in self.log_buffer.readlines():
            try:
                time_part, rest = line.split(' - ', 1)
                level, message = rest.split(' - ', 1)
                logs.append({
                    'time': time_part.strip(),
                    'level': level.strip(),
                    'message': message.strip()
                })
            except:
                continue
        return logs
    def get_logger(self):
        return logging.getLogger() 


# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'output'

class MainApp:
    def __init__(self, log_collector):
        """åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å—"""
        self.scraper = TableScraper(mode='js', driver_path='chromedriver.exe')
        load_dotenv()
        self.ai_assistant = AIDataAssistant(api_key=os.getenv('OPENAI_API_KEY'))
        self.log_collector = log_collector
        self.logger = log_collector.get_logger()

    def run_pipeline(self, url: str):
        """è¿è¡Œæ•°æ®å¤„ç†æµç¨‹ç›´åˆ°è½¬ç½®å®Œæˆ"""
        try:
            # 1. çˆ¬å–è¡¨æ ¼æ•°æ®å¹¶ä¿å­˜ä¸ºExcel
            self.logger.info("å¼€å§‹çˆ¬å–è¡¨æ ¼æ•°æ®...")
            tables = self.scraper.scrape_table(url)
            if not tables:
                raise ValueError("æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼æ•°æ®")
            
            excel_path = os.path.join("output", "financial_data.xlsx")
            try:
                os.makedirs("output", exist_ok=True, mode=0o777)
            except PermissionError:
                self.logger.error("æ— æ³•åˆ›å»ºoutputç›®å½•ï¼Œè¯·æ£€æŸ¥æƒé™")
                raise
            with pd.ExcelWriter(excel_path) as writer:
                sheet_names = ["ä¸»è¦è´¢åŠ¡æŒ‡æ ‡", "èµ„äº§è´Ÿå€ºè¡¨", "åˆ©æ¶¦è¡¨", "ç°é‡‘æµé‡è¡¨"]
                for i, table in enumerate(tables):
                    name = sheet_names[i] if i < len(sheet_names) else f"Sheet{i+1}"
                    table.to_excel(writer, sheet_name=name, index=False)
            self.logger.info(f"è¡¨æ ¼æ•°æ®å·²ä¿å­˜åˆ°: {excel_path}")

            # 2. æ•°æ®è½¬ç½®
            self.logger.info("å¼€å§‹æ•°æ®è½¬ç½®...")
            with pd.ExcelFile(excel_path) as excel:
                sheets = {sheet: pd.read_excel(excel, sheet_name=sheet) for sheet in excel.sheet_names}
            
            for sheet_name, df in sheets.items():
                # å°†ç¬¬ä¸€åˆ—è®¾ä¸ºç´¢å¼•åå†è½¬ç½®
                if len(df.columns) > 0:
                    df = df.set_index(df.columns[0])
                    sheets[sheet_name] = df.T
            
            with pd.ExcelWriter(excel_path) as writer:
                for sheet_name, df in sheets.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)  

            # 3. æ•°å­—è½¬æ¢å¹¶ä¿å­˜å›åŸExcel
            self.logger.info("å¼€å§‹æ•°å­—è½¬æ¢...")
            with pd.ExcelFile(excel_path) as excel:
                sheets = {sheet: pd.read_excel(excel, sheet_name=sheet) for sheet in excel.sheet_names}
            
            converter = NumberConverter()
            for sheet_name, df in sheets.items():
                for col in df.columns:
                    try:
                        df = converter.convert_column(df, col)
                    except Exception as e:
                        logger.warning(f"è·³è¿‡è¡¨ {sheet_name} çš„åˆ— {col}: {str(e)}")
                sheets[sheet_name] = df
            
            with pd.ExcelWriter(excel_path) as writer:
                for sheet_name, df in sheets.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)  # ä¿æŒè½¬ç½®åçš„æ ¼å¼
            
            # 4. æ•°æ®æ¸…æ´—å¹¶ä¿å­˜å›åŸExcel
            self.logger.info("å¼€å§‹æ•°æ®æ¸…æ´—...")
            with pd.ExcelFile(excel_path) as excel:
                sheets = {sheet: pd.read_excel(excel, sheet_name=sheet) for sheet in excel.sheet_names}
            
            cleaner = DataCleaner()
            for sheet_name, df in sheets.items():
                sheets[sheet_name] = cleaner.clean_data(df)
            
            with pd.ExcelWriter(excel_path) as writer:
                for sheet_name, df in sheets.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)  # ä¿æŒè½¬ç½®åçš„æ ¼å¼
            
            self.logger.info("æ•°æ®è½¬ç½®å®Œæˆ!")
            return {
                'status': 'transpose_completed',
                'excel_path': os.path.abspath(excel_path).replace("\\", "/")
            }


        except Exception as e:
            self.logger.error(f"æµç¨‹æ‰§è¡Œå‡ºé”™: {e}")
            raise

    def continue_analysis(self, excel_path):
        """ç»§ç»­æ‰§è¡Œå¯è§†åŒ–åˆ†æå’ŒAIåˆ†æ"""
        try:
            # ç›´æ¥è¿›è¡ŒAIåˆ†æ
            self.logger.info("å¼€å§‹AIåˆ†æ...")
            with pd.ExcelFile(excel_path) as excel:
                # å•sheetåˆ†æ
                for sheet_name in excel.sheet_names:
                    df = pd.read_excel(excel, sheet_name=sheet_name)
                    
                    # æ ¹æ®sheetåç§°é€‰æ‹©åˆ†æç±»å‹
                    if "Sheet1" in sheet_name or "ä¸»è¦è´¢åŠ¡æŒ‡æ ‡" in sheet_name:
                        task = "financial_metrics"
                    elif "èµ„äº§è´Ÿå€ºè¡¨" in sheet_name:
                        task = "balance_sheet"
                    elif "åˆ©æ¶¦è¡¨" in sheet_name:
                        task = "income_statement"
                    elif "ç°é‡‘æµé‡è¡¨" in sheet_name:
                        task = "cash_flow"
                    else:
                        task = "standard"
                    
                    result = self.ai_assistant.analyzer.analyze(
                        df, 
                        task=task,
                        output_md=f"output/{sheet_name}_analysis.md"
                    )
                
                # åˆå¹¶sheet2-sheet4åˆ†æ
                if len(excel.sheet_names) >= 4:
                    combined_data = {}
                    for sheet_name in excel.sheet_names[1:4]:  # sheet2-sheet4
                        df = pd.read_excel(excel, sheet_name=sheet_name)
                        combined_data[sheet_name] = df
                    
                    result = self.ai_assistant.analyzer.analyze_combined(
                        combined_data,
                        output_md="output/æ±‡æ€»åˆ†æ_analysis.md"
                    )
            
            self.logger.info("æ‰€æœ‰æµç¨‹å®Œæˆ!")
            return {}

        except Exception as e:
            self.logger.error(f"åç»­åˆ†æå‡ºé”™: {e}")
            raise

@app.route('/')
def index():
    return render_template('index.html')

from threading import Thread
from flask import jsonify, Response
import time


# å…¨å±€å˜é‡å­˜å‚¨åˆ†æçŠ¶æ€å’Œç»“æœ
analysis_status = {}
analysis_results = {}

def background_analysis(url, task_id):
    try:
        #main_app = MainApp(LogCollector())
        initial_result = main_app.run_pipeline(url)
        
        if initial_result['status'] == 'transpose_completed':
            # å…ˆè¿”å›è½¬ç½®å®ŒæˆçŠ¶æ€
            analysis_results[task_id] = {
                'status': 'transpose_completed',
                'excel_path': initial_result['excel_path'],
                'error': None
            }
            
            # ç»§ç»­æ‰§è¡Œåç»­åˆ†æ
            main_app.continue_analysis(initial_result['excel_path'])
            analysis_results[task_id] = {
                'status': 'completed',
                'error': None
            }

    except Exception as e:
        analysis_results[task_id] = {
            'status': 'error',
            'error': str(e)
        }
@app.route('/logs')
def get_logs():
    logs = log_collector.get_logs()
    return jsonify(logs)

@app.route('/analyze', methods=['POST'])
def analyze():
    url = request.form.get('url')
    if not url:
        url = "https://emweb.securities.eastmoney.com/PC_HKF10/pages/home/index.html?code=03333&type=web&color=w#/newfinancialanalysis"
    
    task_id = str(time.time())
    analysis_status[task_id] = 'processing'
    
    # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†åˆ†æä»»åŠ¡
    thread = Thread(target=background_analysis, args=(url, task_id))
    thread.start()
    
    return jsonify({'task_id': task_id, 'status': 'processing'})

@app.route('/check_status/<task_id>')
def check_status(task_id):
    if task_id in analysis_results:
        result = analysis_results[task_id]
        if result['status'] == 'completed':
            return jsonify({
                'status': 'completed',
                'redirect': f'/results?task_id={task_id}'
            })
        elif result['status'] == 'transpose_completed':
            return jsonify({
                'status': 'transpose_completed',
                'redirect': f'/results?task_id={task_id}'
            })
        else:
            return jsonify({
                'status': 'error',
                'error': result['error']
            })
    elif task_id in analysis_status:
        return jsonify({'status': 'processing'})
    else:
        return jsonify({'status': 'not_found'}), 404

@app.route('/results')
def show_results():
    task_id = request.args.get('task_id')
    if not task_id or task_id not in analysis_results:
        return redirect(url_for('index'))

    result = analysis_results[task_id]
    logs = log_collector.get_logs()

    if result['status'] in ['completed', 'transpose_completed']:
        excel_path = result.get('excel_path')
        selected_year = request.args.get('year') # è·å–é€‰æ‹©çš„å¹´ä»½/æ—¶é—´ç‚¹

        key_metrics = []
        available_years = []
        excel_tables = {}
        metrics_df = None # ç”¨äºå­˜å‚¨ä¸»è¦è´¢åŠ¡æŒ‡æ ‡çš„DataFrame

        try:
            xls = pd.ExcelFile(excel_path)
            for sheet in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=sheet)
                html_table = df.to_html(classes='table table-bordered table-striped', index=True)
                excel_tables[sheet] = html_table

                # å­˜å‚¨ "ä¸»è¦è´¢åŠ¡æŒ‡æ ‡" DataFrame å¹¶æå–å¯ç”¨å¹´ä»½
                if sheet == "ä¸»è¦è´¢åŠ¡æŒ‡æ ‡" and not df.empty:
                    metrics_df = df
                    if len(df.columns) > 1:
                        # å¯ç”¨å¹´ä»½/æ—¶é—´ç‚¹æ˜¯é™¤äº†ç¬¬ä¸€åˆ—ï¼ˆæŒ‡æ ‡åç§°ï¼‰ä¹‹å¤–çš„æ‰€æœ‰åˆ—
                        available_years = df.columns[1:].tolist()
                        # å¦‚æœæ²¡æœ‰é€‰æ‹©å¹´ä»½ï¼Œæˆ–é€‰æ‹©çš„å¹´ä»½æ— æ•ˆï¼Œåˆ™é»˜è®¤é€‰æ‹©æœ€æ–°çš„ï¼ˆæœ€åä¸€åˆ—ï¼‰
                        if not selected_year or selected_year not in available_years:
                            selected_year = available_years[-1] if available_years else None
                    else:
                         logger.warning("ä¸»è¦è´¢åŠ¡æŒ‡æ ‡ sheet æ²¡æœ‰æ•°æ®åˆ—ã€‚")


            # å¦‚æœæˆåŠŸè¯»å–äº†æŒ‡æ ‡è¡¨å¹¶ä¸”é€‰å®šäº†å¹´ä»½ï¼Œåˆ™æå–è¯¥å¹´ä»½çš„æ•°æ®
            if metrics_df is not None and selected_year and selected_year in available_years:
                metric_column_name = metrics_df.columns[0] # æŒ‡æ ‡åç§°åˆ—å
                num_metrics_to_show = min(5, len(metrics_df)) # æœ€å¤šæ˜¾ç¤º5ä¸ª

                for i in range(num_metrics_to_show):
                    metric_name = metrics_df.iloc[i][metric_column_name]
                    metric_value = metrics_df.iloc[i][selected_year] # ä½¿ç”¨é€‰å®šå¹´ä»½çš„åˆ—

                    # æ ¼å¼åŒ–æ•°å€¼
                    try:
                        formatted_value = f"{float(metric_value):,.2f}" if pd.notna(metric_value) else "N/A"
                    except (ValueError, TypeError):
                        formatted_value = str(metric_value) if pd.notna(metric_value) else "N/A"

                    key_metrics.append({
                        'name': metric_name,
                        'value': formatted_value
                        # 'period' ä¸å†å•ç‹¬é™„åŠ ï¼Œå› ä¸ºå¹´ä»½å·²é€‰å®š
                    })
            elif metrics_df is not None and not available_years:
                 logger.warning("ä¸»è¦è´¢åŠ¡æŒ‡æ ‡ sheet å­˜åœ¨ï¼Œä½†æœªèƒ½æå–åˆ°ä»»ä½•å¹´ä»½/æ—¶é—´ç‚¹åˆ—ã€‚")


        except Exception as e:
            logger.error(f"è¯»å– Excel æˆ–æå–æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return render_template('results.html',
                                    error=f"Excelè¯»å–æˆ–æŒ‡æ ‡æå–å¤±è´¥: {e}",
                                    excel_path=excel_path,
                                    excel_tables={},
                                    visualizations={},
                                    key_metrics=[],
                                    available_years=[],
                                    selected_year=None,
                                    task_id=task_id, # ä¼ é€’ task_id
                                    logs=logs
                               )

        # æˆåŠŸæ—¶ä¼ é€’æ‰€æœ‰éœ€è¦çš„æ•°æ®
        return render_template('results.html',
                               excel_path=excel_path,
                               excel_tables=excel_tables,
                               visualizations={},
                               key_metrics=key_metrics,
                               available_years=available_years, # ä¼ é€’å¯ç”¨å¹´ä»½åˆ—è¡¨
                               selected_year=selected_year,   # ä¼ é€’é€‰å®šå¹´ä»½
                               task_id=task_id, # ä¼ é€’ task_id ä»¥ä¾¿é‡æ–°åŠ è½½æ—¶ä¿ç•™
                               error=None,
                               logs=logs
                               )
    else:
        # åœ¨å…¶ä»–é”™è¯¯æƒ…å†µä¸‹ä¹Ÿä¼ é€’ç©ºæ•°æ®
        return render_template('results.html',
                               error=result.get('error'),
                               excel_path=None,
                               excel_tables={},
                               visualizations={},
                               key_metrics=[],
                               available_years=[],
                               selected_year=None,
                               task_id=task_id, # ä¼ é€’ task_id
                               logs=logs
                               )



@app.route('/download/<file_type>')
def download(file_type):
    if file_type == 'excel':
        filename = 'financial_data.xlsx'
    elif file_type == 'analysis':
        filename = 'combined_analysis.md'
    else:
        return "æ— æ•ˆçš„æ–‡ä»¶ç±»å‹", 404
    
    return send_from_directory(
        app.config['UPLOAD_FOLDER'],
        filename,
        as_attachment=True
    )

@app.route('/static/<filename>')
def static_files(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/du_point_analysis')
def du_point_analysis():
    excel_path = request.args.get('excel_path')
    if not excel_path:
        return redirect(url_for('index'))

    
    excel_path = os.path.abspath(excel_path).replace("\\", "/")
    print(f"ğŸ“‚ du_point_analysis æ”¶åˆ° Excel è·¯å¾„: {excel_path}")

    try:
        from du_point_unit import create_app as create_du_point_app, run_app
        du_point_app, _, _ = create_du_point_app(excel_path=excel_path)
        
        # ç¡®ä¿åº”ç”¨å·²æ­£ç¡®åˆå§‹åŒ–
        if du_point_app.layout is None:
            du_point_app.layout = html.Div("æœé‚¦åˆ†æåŠ è½½ä¸­...")

        from threading import Thread
        thread = Thread(target=run_app, args=(du_point_app,))
        thread.daemon = True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
        thread.start()

        return f"""
        <html>
            <head><meta charset="utf-8"><title>æœé‚¦åˆ†æå¯åŠ¨ä¸­</title></head>
            <body>
                <p>æœé‚¦åˆ†æå·²å¯åŠ¨ï¼Œè¯·ç‚¹å‡»æ‰“å¼€ï¼š</p>
                <a href="http://127.0.0.1:8050/" target="_blank">http://127.0.0.1:8050/</a>
                <p>å¦‚æœé¡µé¢æ²¡æœ‰è‡ªåŠ¨æ‰“å¼€ï¼Œè¯·ç¨ç­‰å‡ ç§’åæ‰‹åŠ¨ç‚¹å‡»é“¾æ¥</p>
            </body>
        </html>
        """
    except Exception as e:
        logger.error(f"æœé‚¦åˆ†æå¯åŠ¨å¤±è´¥: {e}")
        return render_template('results.html',
                               error=f"æœé‚¦åˆ†æå¯åŠ¨å¤±è´¥: {e}",
                               excel_path=excel_path)

import glob # å¯¼å…¥ glob æ¨¡å—

@app.route('/ai_analysis')
def show_ai_analysis():
    """æ˜¾ç¤ºAIåˆ†æç»“æœé¡µé¢ï¼Œå…è®¸é€šè¿‡ä¸‹æ‹‰åˆ—è¡¨é€‰æ‹©å•ä¸ª .md æ–‡ä»¶"""
    output_dir = app.config['UPLOAD_FOLDER']
    all_md_files_paths = glob.glob(os.path.join(output_dir, '*.md'))
    # è·å–æ–‡ä»¶ååˆ—è¡¨å¹¶æŒ‰å­—æ¯æ’åº
    all_md_files = sorted([os.path.basename(f) for f in all_md_files_paths])
    
    # è·å–è¯·æ±‚çš„æ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ’åºåçš„ç¬¬ä¸€ä¸ªæ–‡ä»¶
    selected_file = request.args.get('file', all_md_files[0] if all_md_files else None)
    
    html_analysis_result = ""
    error_message = None

    if not all_md_files:
        error_message = "åœ¨ output ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½• AI åˆ†ææŠ¥å‘Šæ–‡ä»¶ (.md)ã€‚"
        logger.warning(error_message)
    elif selected_file not in all_md_files:
        error_message = f"è¯·æ±‚çš„æ–‡ä»¶ '{selected_file}' ä¸å­˜åœ¨ã€‚"
        logger.warning(error_message)
        # å¦‚æœè¯·æ±‚çš„æ–‡ä»¶æ— æ•ˆï¼Œåˆ™é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ–‡ä»¶
        selected_file = all_md_files[0] if all_md_files else None # ç¡®ä¿åœ¨æ–‡ä»¶åˆ—è¡¨ä¸ºç©ºæ—¶ä¸ä¼šå‡ºé”™
    
    # å¦‚æœæœ‰é€‰å®šçš„æ–‡ä»¶ï¼ˆæ— è®ºæ˜¯é»˜è®¤è¿˜æ˜¯è¯·æ±‚çš„ï¼‰ï¼Œåˆ™è¯»å–å¹¶æ˜¾ç¤º
    if selected_file:
        selected_file_path = os.path.join(output_dir, selected_file)
        try:
            with open(selected_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # å°† Markdown è½¬æ¢ä¸º HTML
            html_analysis_result = markdown.markdown(content, extensions=['extra', 'sane_lists'])
            logger.info(f"æ­£åœ¨æ˜¾ç¤º AI åˆ†ææ–‡ä»¶: {selected_file}")
        except Exception as e:
            error_message = f"è¯»å–æ–‡ä»¶ {selected_file} æ—¶å‡ºé”™: {e}"
            logger.error(error_message)
            html_analysis_result = f"<p>é”™è¯¯: {error_message}</p>"

    return render_template('ai_analysis.html',
                           analysis_result=html_analysis_result,
                           md_files=all_md_files, # ä½¿ç”¨æ’åºåçš„æ–‡ä»¶åˆ—è¡¨
                           selected_file=selected_file,
                           error_message=error_message)

@app.route('/reset_and_home')
def reset_and_home():
    """æ¸…é™¤æŒ‡å®šä»»åŠ¡çš„çŠ¶æ€å’Œç»“æœï¼Œå¹¶é‡å®šå‘åˆ°é¦–é¡µ"""
    task_id = request.args.get('task_id')
    if task_id:
        # ä»å­—å…¸ä¸­ç§»é™¤ä»»åŠ¡æ¡ç›®ï¼Œä½¿ç”¨ pop å¹¶æä¾›é»˜è®¤å€¼ä»¥é¿å… KeyErrors
        analysis_status.pop(task_id, None)
        analysis_results.pop(task_id, None)
        logger.info(f"ä»»åŠ¡ {task_id} å·²è¢«é‡ç½®ã€‚")
    else:
        logger.warning("å°è¯•é‡ç½®ä»»åŠ¡ï¼Œä½†æœªæä¾› task_idã€‚")
    
    # æ¸…ç©ºæ—¥å¿—ç¼“å†²åŒºï¼Œä»¥ä¾¿æ–°ä»»åŠ¡ä»å¹²å‡€çš„æ—¥å¿—å¼€å§‹
    log_collector.log_buffer.truncate(0)
    log_collector.log_buffer.seek(0)
    logger.info("æ—¥å¿—ç¼“å†²åŒºå·²æ¸…ç©ºã€‚")

    return redirect(url_for('index'))


log_collector = LogCollector()
logger = log_collector.get_logger()
main_app = MainApp(log_collector)


if __name__ == "__main__":
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    app.run(debug=False)
